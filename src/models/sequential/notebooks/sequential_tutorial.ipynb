{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Recommendation Models Tutorial\n",
    "\n",
    "This notebook demonstrates time-aware recommendation using sequential models (RNN/LSTM/Attention).\n",
    "\n",
    "## Overview\n",
    "- **Sequential Models**: Capture temporal patterns in user behavior\n",
    "- **Time-Aware**: Consider when users interacted with items\n",
    "- **Session-Based**: Model short-term and long-term preferences\n",
    "- **Next-Item Prediction**: Predict what user will interact with next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install torch pandas scikit-learn numpy matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "from model import (\n",
    "    SequentialRecommender, AttentionalSequentialRecommender,\n",
    "    SessionBasedRecommender\n",
    ")\n",
    "from data_loader import SequentialDataLoader\n",
    "from trainer import SequentialTrainer\n",
    "from inference import SequentialInference\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequential Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ratings_path = '../../ml-32m/ratings.csv'\n",
    "movies_path = '../../ml-32m/movies.csv'\n",
    "\n",
    "if not os.path.exists(ratings_path):\n",
    "    print(f\"Please download MovieLens 32M dataset\")\n",
    "else:\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    movies_df = pd.read_csv(movies_path) if os.path.exists(movies_path) else None\n",
    "    \n",
    "    print(f\"Loaded {len(ratings_df):,} ratings\")\n",
    "    print(f\"Date range: {datetime.fromtimestamp(ratings_df['timestamp'].min())} to {datetime.fromtimestamp(ratings_df['timestamp'].max())}\")\n",
    "    \n",
    "    ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "ratings_df['datetime'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "ratings_df['hour'] = ratings_df['datetime'].dt.hour\n",
    "ratings_df['day_of_week'] = ratings_df['datetime'].dt.dayofweek\n",
    "ratings_df['month'] = ratings_df['datetime'].dt.month\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Ratings by hour of day\n",
    "plt.subplot(2, 3, 1)\n",
    "hourly_counts = ratings_df['hour'].value_counts().sort_index()\n",
    "plt.plot(hourly_counts.index, hourly_counts.values)\n",
    "plt.title('Ratings by Hour of Day')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Ratings by day of week\n",
    "plt.subplot(2, 3, 2)\n",
    "daily_counts = ratings_df['day_of_week'].value_counts().sort_index()\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "plt.bar(range(7), daily_counts.values)\n",
    "plt.title('Ratings by Day of Week')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.xticks(range(7), days)\n",
    "\n",
    "# User sequence lengths\n",
    "plt.subplot(2, 3, 3)\n",
    "user_counts = ratings_df['userId'].value_counts()\n",
    "plt.hist(user_counts, bins=50, alpha=0.7)\n",
    "plt.title('User Sequence Lengths')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Time gaps between ratings\n",
    "plt.subplot(2, 3, 4)\n",
    "sample_user = ratings_df['userId'].iloc[0]\n",
    "user_data = ratings_df[ratings_df['userId'] == sample_user].sort_values('timestamp')\n",
    "time_gaps = np.diff(user_data['timestamp']) / 3600  # Convert to hours\n",
    "plt.hist(time_gaps[time_gaps < 168], bins=50, alpha=0.7)  # Show gaps < 1 week\n",
    "plt.title(f'Time Gaps Between Ratings (User {sample_user})')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Rating evolution over time for a user\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(range(len(user_data)), user_data['rating'].values, 'o-', alpha=0.7)\n",
    "plt.title(f'Rating Pattern Over Time (User {sample_user})')\n",
    "plt.xlabel('Rating Index')\n",
    "plt.ylabel('Rating')\n",
    "\n",
    "# Average rating by month\n",
    "plt.subplot(2, 3, 6)\n",
    "monthly_avg = ratings_df.groupby('month')['rating'].mean()\n",
    "plt.plot(monthly_avg.index, monthly_avg.values, 'o-')\n",
    "plt.title('Average Rating by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSample user {sample_user} has {len(user_data)} ratings over {(user_data['timestamp'].max() - user_data['timestamp'].min()) / (24*3600):.1f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequential Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential data loader\n",
    "data_loader = SequentialDataLoader(\n",
    "    ratings_path=ratings_path,\n",
    "    min_interactions=10,   # Users with at least 10 ratings\n",
    "    min_seq_length=5,      # Sequences with at least 5 items\n",
    "    max_seq_length=50      # Maximum sequence length\n",
    ")\n",
    "\n",
    "print(f\"Processed {len(data_loader.user_sequences)} user sequences\")\n",
    "\n",
    "# Analyze sequence statistics\n",
    "seq_lengths = [len(seq) for seq in data_loader.user_sequences.values()]\n",
    "print(f\"Sequence length stats:\")\n",
    "print(f\"  Mean: {np.mean(seq_lengths):.1f}\")\n",
    "print(f\"  Median: {np.median(seq_lengths):.1f}\")\n",
    "print(f\"  Min: {np.min(seq_lengths)}\")\n",
    "print(f\"  Max: {np.max(seq_lengths)}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(seq_lengths, bins=50, alpha=0.7)\n",
    "plt.title('Distribution of User Sequence Lengths')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.axvline(np.mean(seq_lengths), color='red', linestyle='--', label=f'Mean: {np.mean(seq_lengths):.1f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training\n",
    "train_loader, val_loader, test_loader = data_loader.create_data_loaders(\n",
    "    data_type='sequential',  # or 'session' for session-based modeling\n",
    "    batch_size=256,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"  Test samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "# Get model configuration\n",
    "model_config = data_loader.get_model_config()\n",
    "print(f\"\\nModel config: {model_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training - Sequential LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential recommender with LSTM\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "seq_model = SequentialRecommender(\n",
    "    num_items=model_config['num_items'],\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    dropout=0.2,\n",
    "    rnn_type='LSTM'\n",
    ")\n",
    "\n",
    "print(f\"Sequential model parameters: {sum(p.numel() for p in seq_model.parameters()):,}\")\n",
    "print(seq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sequential model\n",
    "seq_trainer = SequentialTrainer(\n",
    "    model=seq_model,\n",
    "    device=device,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "print(\"Training Sequential LSTM model...\")\n",
    "seq_history = seq_trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,  # Increase for better performance\n",
    "    patience=5,\n",
    "    save_dir='../models'\n",
    ")\n",
    "\n",
    "print(f\"Sequential training completed! Best validation loss: {seq_trainer.best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training - Attention-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention-based sequential recommender\n",
    "attention_model = AttentionalSequentialRecommender(\n",
    "    num_items=model_config['num_items'],\n",
    "    embedding_dim=128,\n",
    "    num_heads=8,\n",
    "    num_blocks=2,\n",
    "    dropout=0.2,\n",
    "    max_seq_len=50\n",
    ")\n",
    "\n",
    "print(f\"Attention model parameters: {sum(p.numel() for p in attention_model.parameters()):,}\")\n",
    "\n",
    "# Train attention model\n",
    "attention_trainer = SequentialTrainer(\n",
    "    model=attention_model,\n",
    "    device=device,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "print(\"Training Attention-based model...\")\n",
    "attention_history = attention_trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=8,  # Attention models often converge faster\n",
    "    patience=5,\n",
    "    save_dir='../models'\n",
    ")\n",
    "\n",
    "print(f\"Attention training completed! Best validation loss: {attention_trainer.best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training histories\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(seq_history['val_losses'], label='Sequential LSTM', marker='o')\n",
    "plt.plot(attention_history['val_losses'], label='Attention', marker='s')\n",
    "plt.title('Validation Loss Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(seq_history['val_accuracies'], label='Sequential LSTM', marker='o')\n",
    "plt.plot(attention_history['val_accuracies'], label='Attention', marker='s')\n",
    "plt.title('Validation Accuracy Comparison')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "if seq_history['val_hit_rates'] and attention_history['val_hit_rates']:\n",
    "    plt.plot(seq_history['val_hit_rates'], label='Sequential LSTM', marker='o')\n",
    "    plt.plot(attention_history['val_hit_rates'], label='Attention', marker='s')\n",
    "    plt.title('Hit Rate@10 Comparison')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Hit Rate@10')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Results:\")\n",
    "print(f\"  Sequential LSTM - Loss: {seq_trainer.best_val_loss:.4f}\")\n",
    "print(f\"  Attention Model - Loss: {attention_trainer.best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sequential Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save encoders and create inference\n",
    "data_loader.save_encoders('../models/encoders.pkl')\n",
    "\n",
    "# Use the better performing model (let's use attention model)\n",
    "seq_inference = SequentialInference(\n",
    "    model_path='../models/best_model.pt',\n",
    "    encoders_path='../models/encoders.pkl',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Sequential inference object created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample user sequence for demonstration\n",
    "sample_user_id = list(data_loader.user_sequences.keys())[0]\n",
    "sample_sequence = data_loader.user_sequences[sample_user_id]\n",
    "\n",
    "print(f\"Sample user has sequence of length: {len(sample_sequence)}\")\n",
    "\n",
    "# Convert encoded sequence back to original movie IDs for display\n",
    "original_sequence = []\n",
    "for encoded_item in sample_sequence[:10]:  # Show first 10 items\n",
    "    try:\n",
    "        original_item = data_loader.item_encoder.inverse_transform([encoded_item - 1])[0]\n",
    "        original_sequence.append(original_item)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"\\nUser's recent movie sequence (first 10):\")\n",
    "if movies_df is not None:\n",
    "    for i, movie_id in enumerate(original_sequence):\n",
    "        movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "        if not movie_info.empty:\n",
    "            title = movie_info.iloc[0]['title']\n",
    "            print(f\"  {i+1}. {title}\")\n",
    "        else:\n",
    "            print(f\"  {i+1}. Movie ID {movie_id}\")\n",
    "else:\n",
    "    for i, movie_id in enumerate(original_sequence):\n",
    "        print(f\"  {i+1}. Movie ID {movie_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next items based on this sequence\n",
    "next_items = seq_inference.predict_next_items(\n",
    "    sequence=original_sequence,\n",
    "    top_k=10,\n",
    "    exclude_seen=True\n",
    ")\n",
    "\n",
    "print(f\"\\nNext item predictions based on sequence:\")\n",
    "for i, (movie_id, probability) in enumerate(next_items, 1):\n",
    "    if movies_df is not None:\n",
    "        movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "        if not movie_info.empty:\n",
    "            title = movie_info.iloc[0]['title']\n",
    "            genres = movie_info.iloc[0]['genres']\n",
    "            print(f\"  {i}. {title} (Prob: {probability:.3f})\")\n",
    "            print(f\"     Genres: {genres}\")\n",
    "        else:\n",
    "            print(f\"  {i}. Movie ID {movie_id} (Prob: {probability:.3f})\")\n",
    "    else:\n",
    "        print(f\"  {i}. Movie ID {movie_id} (Prob: {probability:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sequence Continuation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multiple future steps\n",
    "sequence_continuation = seq_inference.predict_sequence_continuation(\n",
    "    sequence=original_sequence[:7],  # Use first 7 items\n",
    "    num_steps=5\n",
    ")\n",
    "\n",
    "print(f\"Sequence continuation prediction (5 future steps):\")\n",
    "print(f\"Starting sequence length: 7 items\")\n",
    "print(f\"\\nPredicted future steps:\")\n",
    "\n",
    "for step, step_predictions in enumerate(sequence_continuation, 1):\n",
    "    print(f\"\\n  Step {step}:\")\n",
    "    for i, (movie_id, prob) in enumerate(step_predictions[:3], 1):  # Show top 3 per step\n",
    "        if movies_df is not None:\n",
    "            movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "            title = movie_info.iloc[0]['title'] if not movie_info.empty else f\"Movie {movie_id}\"\n",
    "            print(f\"    {i}. {title} (Prob: {prob:.3f})\")\n",
    "        else:\n",
    "            print(f\"    {i}. Movie ID {movie_id} (Prob: {prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. User Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user patterns\n",
    "original_user_id = data_loader.user_encoder.inverse_transform([sample_user_id])[0]\n",
    "user_patterns = seq_inference.analyze_user_patterns(original_user_id)\n",
    "\n",
    "print(f\"User Pattern Analysis for User {original_user_id}:\")\n",
    "for key, value in user_patterns.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Visualize user's most frequent items\n",
    "if 'most_frequent_items' in user_patterns:\n",
    "    frequent_items = user_patterns['most_frequent_items']\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot frequency distribution\n",
    "    movie_ids, counts = zip(*frequent_items)\n",
    "    \n",
    "    if movies_df is not None:\n",
    "        labels = []\n",
    "        for movie_id in movie_ids:\n",
    "            movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "            title = movie_info.iloc[0]['title'] if not movie_info.empty else f\"Movie {movie_id}\"\n",
    "            # Truncate long titles\n",
    "            labels.append(title[:30] + '...' if len(title) > 30 else title)\n",
    "    else:\n",
    "        labels = [f\"Movie {mid}\" for mid in movie_ids]\n",
    "    \n",
    "    plt.bar(range(len(labels)), counts)\n",
    "    plt.title(f'Most Frequently Watched Movies - User {original_user_id}')\n",
    "    plt.xlabel('Movie')\n",
    "    plt.ylabel('Watch Count')\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nUser tends to re-watch movies (repeat ratio: {user_patterns.get('repeat_ratio', 0):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Session-Based Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session-based data loaders\n",
    "session_train_loader, session_val_loader, session_test_loader = data_loader.create_data_loaders(\n",
    "    data_type='session',\n",
    "    batch_size=256,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Session-based data loaders:\")\n",
    "print(f\"  Training samples: {len(session_train_loader.dataset)}\")\n",
    "print(f\"  Validation samples: {len(session_val_loader.dataset)}\")\n",
    "print(f\"  Test samples: {len(session_test_loader.dataset)}\")\n",
    "\n",
    "# Create session-based model\n",
    "session_model = SessionBasedRecommender(\n",
    "    num_items=model_config['num_items'],\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=1,\n",
    "    dropout=0.3,\n",
    "    use_attention=True\n",
    ")\n",
    "\n",
    "print(f\"Session model parameters: {sum(p.numel() for p in session_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train session-based model (optional - can be time consuming)\n",
    "# Uncomment to train\n",
    "\n",
    "# session_trainer = SequentialTrainer(\n",
    "#     model=session_model,\n",
    "#     device=device,\n",
    "#     learning_rate=0.001,\n",
    "#     weight_decay=1e-5\n",
    "# )\n",
    "\n",
    "# print(\"Training Session-based model...\")\n",
    "# session_history = session_trainer.train(\n",
    "#     train_loader=session_train_loader,\n",
    "#     val_loader=session_val_loader,\n",
    "#     epochs=5,\n",
    "#     patience=3,\n",
    "#     save_dir='../models'\n",
    "# )\n",
    "\n",
    "print(\"Session-based model created (training skipped for demo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different approaches on the same sequence\n",
    "test_sequence = original_sequence[:8]\n",
    "\n",
    "print(f\"Comparing predictions for sequence of {len(test_sequence)} items:\")\n",
    "if movies_df is not None:\n",
    "    print(\"\\nInput sequence:\")\n",
    "    for i, movie_id in enumerate(test_sequence[-3:], len(test_sequence)-2):  # Show last 3\n",
    "        movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "        title = movie_info.iloc[0]['title'] if not movie_info.empty else f\"Movie {movie_id}\"\n",
    "        print(f\"  {i}. {title}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = seq_inference.predict_next_items(test_sequence, top_k=5)\n",
    "\n",
    "print(f\"\\nNext item predictions:\")\n",
    "for i, (movie_id, prob) in enumerate(predictions, 1):\n",
    "    if movies_df is not None:\n",
    "        movie_info = movies_df[movies_df['movieId'] == movie_id]\n",
    "        title = movie_info.iloc[0]['title'] if not movie_info.empty else f\"Movie {movie_id}\"\n",
    "        genres = movie_info.iloc[0]['genres'] if not movie_info.empty else \"Unknown\"\n",
    "        print(f\"  {i}. {title} (Prob: {prob:.3f})\")\n",
    "        print(f\"     Genres: {genres}\")\n",
    "    else:\n",
    "        print(f\"  {i}. Movie ID {movie_id} (Prob: {prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "### What we accomplished:\n",
    "- ✅ **Temporal Analysis**: Analyzed when users interact with content\n",
    "- ✅ **Sequential Data Processing**: Created time-ordered user sequences\n",
    "- ✅ **Multiple Architectures**: Trained LSTM and Attention-based models\n",
    "- ✅ **Next-Item Prediction**: Predicted what users will watch next\n",
    "- ✅ **Sequence Continuation**: Multi-step future predictions\n",
    "- ✅ **User Pattern Analysis**: Analyzed individual user behaviors\n",
    "- ✅ **Session-Based Modeling**: Short-term preference modeling\n",
    "\n",
    "### Key Insights:\n",
    "1. **Time Matters**: Users have different viewing patterns by hour/day\n",
    "2. **Sequence Length**: Users vary greatly in interaction history\n",
    "3. **Attention vs LSTM**: Attention models often perform better for longer sequences\n",
    "4. **Repeat Behavior**: Users often re-watch content (important for recommendations)\n",
    "\n",
    "### Next Steps:\n",
    "1. **Longer Training**: Train for more epochs for better convergence\n",
    "2. **Hyperparameter Tuning**: Optimize embedding dimensions, learning rates\n",
    "3. **Advanced Architectures**: Try Transformer-based models\n",
    "4. **Multi-Task Learning**: Predict ratings + next items simultaneously\n",
    "5. **Session Detection**: Automatic session boundary detection\n",
    "6. **Real-Time Inference**: Deploy for live recommendation systems\n",
    "\n",
    "### Integration with Discord Bot:\n",
    "Sequential models enable powerful time-aware features:\n",
    "- **Binge Recommendations**: \"What should I watch next in this series?\"\n",
    "- **Session Continuity**: \"Continue my weekend movie marathon\"\n",
    "- **Temporal Patterns**: \"Recommend based on my Friday night viewing\"\n",
    "- **Sequence Analysis**: \"Analyze my viewing evolution over time\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}